"""
FastAPI Server - Network Quality Prediction API
H·ªó tr·ª£ Mode 2 (Scenario) v√† Mode 3 (Simple)
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import sys
import os
import time

# --- Th√™m project root v√†o sys.path ---
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
BASE_DIR = PROJECT_ROOT

# ==================== IMPORTS ====================
# 1. Import c√°c routers
from .routers import predict as predict_router
from .routers import scenarios as scenarios_router

# 2. Import c√°c services
from utils.model_wrapper import ModelWrapper
from .services.scenario_manager import ScenarioManager
from .services.smart_estimator import SmartEstimator

# 3. Import c√°c response models 
from .models.response_models import HealthResponse, PredictionResponse

# 4. --- Import Socket.IO ---
import socketio

# Setup logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== FASTAPI APP ====================

app = FastAPI(
    title="Network Quality Prediction API",
    description="D·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng m·∫°ng v·ªõi Mode 2 (Scenario) v√† Mode 3 (Simple)",
    version="1.1.0" # C·∫≠p nh·∫≠t version
)

# CORS middleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== GLOBAL ERROR HANDLERS ====================

@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    logger.error(f"ValueError: {str(exc)}")
    return JSONResponse(status_code=400, content={"error": "ValidationError", "message": str(exc)})

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unexpected error: {str(exc)}")
    return JSONResponse(status_code=500, content={"error": "InternalServerError", "message": "An unexpected error occurred"})

# ==================== GLOBAL INSTANCES ====================

model_wrapper = None
scenario_manager = None
smart_estimator = None

@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    global model_wrapper, scenario_manager, smart_estimator
    
    start_time = time.time()
    
    try:
        logger.info("=" * 80)
        logger.info("üöÄ Starting Network Quality Prediction API Server (v1.1.0)...")
        logger.info("=" * 80)
        logger.info(f"üìÅ Project root: {PROJECT_ROOT}")
        logger.info(f"üìÅ Base directory: {BASE_DIR}")
        
        # --- 1. Load Model ---
        logger.info("\nüì¶ Loading ML model...")
        try:
            # Truy·ªÅn BASE_DIR v√†o ModelWrapper
            model_wrapper = ModelWrapper(base_dir=BASE_DIR)
            logger.info("‚úÖ Model loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to load model: {str(e)}")
            raise
        
        # --- 2. Load Scenarios ---
        logger.info("\nüé¨ Loading scenarios...")
        try:
            scenario_manager = ScenarioManager()
            logger.info(f"‚úÖ Loaded {len(scenario_manager.scenarios)} scenarios")
        except Exception as e:
            logger.error(f"‚ùå Failed to load scenarios: {str(e)}")
            raise
        
        # --- 3. Initialize Estimator ---
        logger.info("\nü§ñ Initializing smart estimator...")
        try:
            smart_estimator = SmartEstimator()
            logger.info("‚úÖ Smart estimator ready")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize estimator: {str(e)}")
            raise
            
        # --- 4. Inject dependencies v√†o Routers ---
        # G·ª≠i c√°c services ƒë√£ kh·ªüi t·∫°o v√†o c√°c file router
        logger.info("\nüîó Injecting dependencies into routers...")
        predict_router.set_dependencies(model_wrapper, scenario_manager, smart_estimator)
        scenarios_router.set_dependencies(scenario_manager)
        logger.info("‚úÖ Dependencies injected")

        elapsed_time = time.time() - start_time
        logger.info("\n" + "=" * 80)
        logger.info(f"üéâ Server ready to accept requests! (took {elapsed_time:.2f}s)")
        logger.info(f"üìö API Docs: http://localhost:8000/docs")
        logger.info("=" * 80 + "\n")
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        logger.critical("=" * 80)
        logger.critical(f"‚ùå Startup failed after {elapsed_time:.2f}s: {str(e)}")
        logger.critical("=" * 80)
        raise

# ==================== ENDPOINTS ====================

app.include_router(predict_router.router)
app.include_router(scenarios_router.router)


@app.get("/", tags=["Root"])
async def root():
    """Root endpoint"""
    return {
        "message": "Network Quality Prediction API (Modes: Scenario, Simple, Real-time)",
        "version": "1.2.0",
        "rest_api_docs": "/docs",
        "websocket_path": "/ws/socket.io"
    }

@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check(detailed: bool = False):
    """Health check endpoint"""
    try:
        if not model_wrapper or not scenario_manager:
            raise HTTPException(status_code=503, detail="Services not initialized")
        
        model_health = model_wrapper.health_check()
        
        all_ready = all([
            model_health.get('ready', False),
            scenario_manager.scenarios,
            smart_estimator is not None
        ])
        
        status = "healthy" if all_ready else "degraded"
        
        health_response = HealthResponse(
            status=status,
            model_loaded=model_health.get('model_loaded', False),
            scenarios_loaded=len(scenario_manager.scenarios),
            version="1.1.0"
        )
        
        logger.info(f"Health check - Status: {status}")
        return health_response
        
    except Exception as e:
        logger.error(f"Health check error: {str(e)}")
        raise HTTPException(status_code=500, detail="Health check failed")

# ==========================================================
# --- C√ÄI ƒê·∫∂T SOCKET.IO (WEBSOCKET) ---
# ==========================================================

# 1. T·∫°o ƒë·ªëi t∆∞·ª£ng Socket.IO Server (sio)
sio = socketio.AsyncServer(
    async_mode="asgi",
    cors_allowed_origins="*", # Cho ph√©p React v√† Worker k·∫øt n·ªëi
    logger=True,
    engineio_logger=True
)

# 2. T·∫°o ·ª©ng d·ª•ng ASGI cho Socket.IO
socket_app = socketio.ASGIApp(
    sio,
    socketio_path="/ws/socket.io"
)

# 3. Mount ·ª©ng d·ª•ng Socket.IO v√†o FastAPI
# B·∫•t k·ª≥ request n√†o t·ªõi /ws ƒë·ªÅu s·∫Ω do socket_app x·ª≠ l√Ω
app.mount("/ws", socket_app)

# 4. --- B·ªô l∆∞u tr·ªØ tr·∫°ng th√°i ---
# D√πng ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu t·∫°m th·ªùi t·ª´ Worker v√† React
# Key l√† `sid` (session ID) c·ªßa client, value l√† dict ch·ª©a metrics v√† context
client_state = {}

async def trigger_prediction(sid: str):
    """
    H√†m l√µi: Khi c√≥ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu (metrics + context),
    g·ªçi SmartEstimator v√† Model, sau ƒë√≥ g·ª≠i tr·∫£ k·∫øt qu·∫£.
    """
    global model_wrapper, smart_estimator
    
    state = client_state.get(sid)
    
    # Ki·ªÉm tra xem ƒë√£ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu ch∆∞a
    if not state or "metrics" not in state or "context" not in state:
        logger.debug(f"[{sid}] Ch∆∞a ƒë·ªß d·ªØ li·ªáu, ƒëang ch·ªù...")
        return

    try:
        logger.info(f"[{sid}] ƒê√£ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu, b·∫Øt ƒë·∫ßu d·ª± ƒëo√°n...")
        
        # 1. Gom 9 th√¥ng s·ªë
        # 4 t·ª´ worker, 5 t·ª´ react
        simple_input = {
            **state["metrics"], # G·ªìm: latency, throughput, battery_level, signal_strength
            **state["context"]  # G·ªìm: user_speed, user_activity, device_type, location, connection_type
        }
        
        # 2. ∆Ø·ªõc t√≠nh (Gi·ªëng h·ªát predict_simple)
        full_params = smart_estimator.estimate(simple_input)
        logger.info(f"[{sid}] ƒê√£ ∆∞·ªõc t√≠nh {len(full_params)} th√¥ng s·ªë.")
        
        # 3. D·ª± ƒëo√°n (Gi·ªëng h·ªát predict_simple)
        result = model_wrapper.predict(full_params)
        logger.info(f"[{sid}] K·∫øt qu·∫£: {result['prediction_label']}")

        # 4. Chu·∫©n b·ªã response (Gi·ªëng h·ªát predict_simple)
        response = PredictionResponse(
            prediction=result['prediction'],
            prediction_label=result['prediction_label'],
            confidence=result['confidence'],
            probabilities=result['probabilities'],
            message="Prediction based on real-time auto-collected metrics",
            mode="realtime", # Mode m·ªõi
            metadata={
                "estimated_features_dict": full_params, # G·ª≠i to√†n b·ªô params ƒë√£ ∆∞·ªõc t√≠nh
                "contexts_used": state["context"]
            }
        )
        
        # 5. G·ª≠i k·∫øt qu·∫£ NG∆Ø·ª¢C L·∫†I cho React Dashboard
        await sio.emit(
            "prediction_update",  # T√™n s·ª± ki·ªán
            response.model_dump(),  # Chuy·ªÉn Pydantic model v·ªÅ dict
            to=sid                   # Ch·ªâ g·ª≠i cho client n√†y
        )
        logger.info(f"[{sid}] ƒê√£ g·ª≠i 'prediction_update' cho client.")

    except Exception as e:
        logger.error(f"[{sid}] L·ªói khi d·ª± ƒëo√°n real-time: {e}")
        # G·ª≠i l·ªói v·ªÅ cho React
        await sio.emit("prediction_error", {"error": str(e)}, to=sid)

# 5. --- C√°c tr√¨nh x·ª≠ l√Ω s·ª± ki·ªán (Event Handlers) ---

@sio.event
async def connect(sid, environ, auth):
    """Client (Worker ho·∫∑c React) k·∫øt n·ªëi"""
    logger.info(f"üì° Client ƒë√£ k·∫øt n·ªëi: {sid}")
    # Kh·ªüi t·∫°o b·ªô l∆∞u tr·ªØ tr·∫°ng th√°i r·ªóng cho client n√†y
    client_state[sid] = {}

@sio.event
async def disconnect(sid):
    """Client ng·∫Øt k·∫øt n·ªëi"""
    logger.warning(f"üîå Client ƒë√£ ng·∫Øt k·∫øt n·ªëi: {sid}")
    # X√≥a tr·∫°ng th√°i c·ªßa client n√†y
    if sid in client_state:
        del client_state[sid]

@sio.event
async def worker_metrics(sid, data):
    """
    Nh·∫≠n d·ªØ li·ªáu t·ª´ 'worker.py' (4 th√¥ng s·ªë)
    """
    logger.info(f"[{sid}] Nh·∫≠n 'worker_metrics': {data}")
    if sid in client_state:
        client_state[sid]["metrics"] = data
        # G·ªçi h√†m l√µi ƒë·ªÉ ki·ªÉm tra v√† d·ª± ƒëo√°n
        await trigger_prediction(sid)

@sio.event
async def context_update(sid, data):
    """
    Nh·∫≠n d·ªØ li·ªáu t·ª´ 'React Dashboard' (5 th√¥ng s·ªë b·ªëi c·∫£nh)
    """
    logger.info(f"[{sid}] Nh·∫≠n 'context_update': {data}")
    if sid in client_state:
        client_state[sid]["context"] = data
        # G·ªçi h√†m l√µi ƒë·ªÉ ki·ªÉm tra v√† d·ª± ƒëo√°n
        await trigger_prediction(sid)

# ==================== RUN SERVER ====================
if __name__ == "__main__":
    print("="*80)
    print("üöÄ NETWORK QUALITY PREDICTION SERVER (v1.2.0 - Real-time)")
    print("="*80)
    print("\nüìç Server s·∫Ω start on: http://localhost:8000")
    print("üìö API Docs (REST): http://localhost:8000/docs")
    print(f"üì° Socket.IO (WS) listening on: /ws/socket.io")
    print("\n‚è≥ Starting server...\n")
    
    # uvicorn.run s·∫Ω t·ª± ƒë·ªông ch·∫°y 'app' (ƒë√£ bao g·ªìm c·∫£ FastAPI v√† Socket.IO)
    uvicorn.run(
        "server.main:app", 
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )