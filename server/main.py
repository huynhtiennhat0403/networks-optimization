"""
FastAPI Server - Network Quality Prediction API
H·ªó tr·ª£ Mode 2 (Scenario) v√† Mode 3 (Simple)
FIXED: TCP Thread -> Socket.IO Bridge
FIXED: 'NoneType' object is not a mapping error
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import sys
import os
import time
import asyncio 

from .tcp_server import TCPServer

# --- Th√™m project root v√†o sys.path ---
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
BASE_DIR = PROJECT_ROOT

# ==================== IMPORTS ====================
from .routers import predict as predict_router
from .routers import scenarios as scenarios_router
from utils.model_wrapper import ModelWrapper
from .services.scenario_manager import ScenarioManager
from .services.smart_estimator import SmartEstimator
from .services.recommendation_service import RecommendationService
from .models.response_models import HealthResponse, PredictionResponse
import socketio

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== FASTAPI APP ====================

app = FastAPI(
    title="Network Quality Prediction API",
    description="D·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng m·∫°ng v·ªõi Mode 2 (Scenario) v√† Mode 3 (Simple)",
    version="1.1.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== GLOBAL ERROR HANDLERS ====================
@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    return JSONResponse(status_code=400, content={"error": "ValidationError", "message": str(exc)})

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    return JSONResponse(status_code=500, content={"error": "InternalServerError", "message": "An unexpected error occurred"})

# ==================== GLOBAL INSTANCES ====================

model_wrapper = None
scenario_manager = None
smart_estimator = None
recommendation_service = None
server_loop = None 

# Socket.IO Setup
sio = socketio.AsyncServer(
    async_mode="asgi",
    cors_allowed_origins="*",
    logger=False, 
    engineio_logger=False
)
socket_app = socketio.ASGIApp(sio, other_asgi_app=app, socketio_path="/ws/socket.io")

# Global State
global_state = {
    "metrics": None,
    "context": None, # Ban ƒë·∫ßu l√† None
    "react_sid": None 
}

@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    global model_wrapper, scenario_manager, smart_estimator, recommendation_service
    global server_loop
    
    # B·∫ÆT L·∫§Y EVENT LOOP HI·ªÜN T·∫†I
    server_loop = asyncio.get_running_loop()
    
    try:
        logger.info("üöÄ Starting Network Quality Prediction API Server...")
        
        # Load Model
        model_wrapper = ModelWrapper(base_dir=BASE_DIR)
        
        # Load Scenarios
        scenario_manager = ScenarioManager()
        
        # Initialize Estimator
        smart_estimator = SmartEstimator()

        # Init Recommendation
        recommendation_service = RecommendationService(base_dir=BASE_DIR)
            
        # Inject dependencies
        predict_router.set_dependencies(model_wrapper, scenario_manager, smart_estimator, recommendation_service)
        scenarios_router.set_dependencies(scenario_manager)

        # Start TCP Server
        try:
            # L∆∞u √Ω port ph·∫£i kh·ªõp v·ªõi worker (9500)
            tcp_server = TCPServer(host="0.0.0.0", port=9500, callback_function=process_tcp_data)
            tcp_server.start() 
            logger.info("‚úÖ TCP Server started on port 9500")
        except Exception as e:
            logger.error(f"‚ùå Failed to start TCP Server: {e}")

    except Exception as e:
        logger.critical(f"‚ùå Startup failed: {str(e)}")
        raise

# === H√ÄM CALLBACK X·ª¨ L√ù D·ªÆ LI·ªÜU T·ª™ TCP ===
def process_tcp_data(payload: dict):
    """
    H√†m n√†y ch·∫°y trong Thread ri√™ng c·ªßa TCP Server.
    """
    global smart_estimator, model_wrapper, recommendation_service
    global global_state, server_loop, sio 
    
    try:
        if payload.get("type") != "worker_data":
            return "Invalid data type"

        metrics_data = payload.get("data", {})
        
        # L·∫•y context hi·ªán t·∫°i t·ª´ React. N·∫øu None th√¨ d√πng dict r·ªóng {}
        current_context = global_state.get("context") or {}
        
        # G·ªôp metrics t·ª´ Worker + Context t·ª´ React
        combined_input = {**metrics_data, **current_context}
        
        # 1. Estimate
        try:
            full_params = smart_estimator.estimate(combined_input)
        except Exception as e:
            logger.warning(f"L·ªói estimate: {e}")
            return "Estimation Error"

        # 2. Predict
        result = model_wrapper.predict(full_params)
        
        # 3. Recommendation
        recommendation = recommendation_service.get_recommendation(
            full_params, 
            result['prediction_label']
        )

        logger.info(f"üîÆ TCP Prediction: {result['prediction_label']}")
        
        # --- B. C·∫¶U N·ªêI SANG REACTJS (BRIDGE) ---
        react_sid = global_state.get("react_sid")
        
        if react_sid and server_loop:
            response_data = PredictionResponse(
                prediction=result['prediction'],
                prediction_label=result['prediction_label'],
                confidence=result['confidence'],
                probabilities=result['probabilities'],
                message="Real-time update from TCP Worker",
                mode="realtime",
                metadata={
                    "estimated_features_dict": full_params,
                    "contexts_used": current_context
                },
                insight=recommendation
            ).model_dump()

            asyncio.run_coroutine_threadsafe(
                sio.emit("prediction_update", response_data, to=react_sid),
                server_loop
            )
            logger.info(f"‚ö° ƒê√£ b·∫Øn t√≠n hi·ªáu update sang React (SID: {react_sid})")
        else:
            # Kh√¥ng log debug li√™n t·ª•c ƒë·ªÉ ƒë·ª° r√°c log
            pass

        return result['prediction_label']

    except Exception as e:
        logger.error(f"L·ªói x·ª≠ l√Ω TCP data: {e}")
        return "Error"

# ==================== ENDPOINTS ====================

app.include_router(predict_router.router)
app.include_router(scenarios_router.router)

@app.get("/", tags=["Root"])
async def root():
    return {
        "message": "Network Quality Prediction API",
        "version": "1.2.0"
    }

@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check(detailed: bool = False):
    status = "healthy" if model_wrapper else "degraded"
    return HealthResponse(
        status=status,
        model_loaded=True,
        scenarios_loaded=len(scenario_manager.scenarios),
        version="1.1.0"
    )

# ==================== SOCKET.IO EVENTS ====================

@sio.event
async def connect(sid, environ, auth):
    logger.info(f"üì° Client Socket k·∫øt n·ªëi: {sid}")

@sio.event
async def disconnect(sid):
    if sid == global_state.get("react_sid"):
        global_state["react_sid"] = None
        logger.warning(f"üîå React Dashboard ng·∫Øt k·∫øt n·ªëi: {sid}")

@sio.event
async def start_prediction(sid, data):
    """
    React g·ª≠i context v√† b·∫Øt ƒë·∫ßu phi√™n ƒëo
    """
    logger.info(f"[{sid}] React b·∫Øt ƒë·∫ßu phi√™n ƒëo Real-time")
    global_state["context"] = data
    global_state["react_sid"] = sid

if __name__ == "__main__":
    uvicorn.run(
        "server.main:socket_app", 
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )