"""
FastAPI Server - Network Quality Prediction API
H·ªó tr·ª£ Mode 2 (Scenario) v√† Mode 3 (Simple)
"""

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import sys
import os
import time

# --- Th√™m project root v√†o sys.path ---
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
BASE_DIR = PROJECT_ROOT

# ==================== IMPORTS ====================
# 1. Import c√°c routers
from .routers import predict as predict_router
from .routers import scenarios as scenarios_router

# 2. Import c√°c services
from utils.model_wrapper import ModelWrapper
from .services.scenario_manager import ScenarioManager
from .services.smart_estimator import SmartEstimator
from .services.recommendation_service import RecommendationService

# 3. Import c√°c response models 
from .models.response_models import HealthResponse, PredictionResponse

# 4. --- Import Socket.IO ---
import socketio

# Setup logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== FASTAPI APP ====================

app = FastAPI(
    title="Network Quality Prediction API",
    description="D·ª± ƒëo√°n ch·∫•t l∆∞·ª£ng m·∫°ng v·ªõi Mode 2 (Scenario) v√† Mode 3 (Simple)",
    version="1.1.0" # C·∫≠p nh·∫≠t version
)

# CORS middleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== GLOBAL ERROR HANDLERS ====================

@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    logger.error(f"ValueError: {str(exc)}")
    return JSONResponse(status_code=400, content={"error": "ValidationError", "message": str(exc)})

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unexpected error: {str(exc)}")
    return JSONResponse(status_code=500, content={"error": "InternalServerError", "message": "An unexpected error occurred"})

# ==================== GLOBAL INSTANCES ====================

model_wrapper = None
scenario_manager = None
smart_estimator = None
recommendation_service = None

@app.on_event("startup")
async def startup_event():
    """Initialize services on startup"""
    global model_wrapper, scenario_manager, smart_estimator
    
    start_time = time.time()
    
    try:
        logger.info("=" * 80)
        logger.info("üöÄ Starting Network Quality Prediction API Server (v1.1.0)...")
        logger.info("=" * 80)
        logger.info(f"üìÅ Project root: {PROJECT_ROOT}")
        logger.info(f"üìÅ Base directory: {BASE_DIR}")
        
        # --- 1. Load Model ---
        logger.info("\nüì¶ Loading ML model...")
        try:
            # Truy·ªÅn BASE_DIR v√†o ModelWrapper
            model_wrapper = ModelWrapper(base_dir=BASE_DIR)
            logger.info("‚úÖ Model loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to load model: {str(e)}")
            raise
        
        # --- 2. Load Scenarios ---
        logger.info("\nüé¨ Loading scenarios...")
        try:
            scenario_manager = ScenarioManager()
            logger.info(f"‚úÖ Loaded {len(scenario_manager.scenarios)} scenarios")
        except Exception as e:
            logger.error(f"‚ùå Failed to load scenarios: {str(e)}")
            raise
        
        # --- 3. Initialize Estimator ---
        logger.info("\nü§ñ Initializing smart estimator...")
        try:
            smart_estimator = SmartEstimator()
            logger.info("‚úÖ Smart estimator ready")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize estimator: {str(e)}")
            raise

        logger.info("\nüß† Initializing recommendation service...")
        try:
            # Kh√¥ng c·∫ßn truy·ªÅn wrapper hay preprocessor n·ªØa
            recommendation_service = RecommendationService(base_dir=BASE_DIR)
            logger.info("‚úÖ Recommendation service ready")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize recommendation service: {e}")
            raise
            
        # --- 4. Inject dependencies v√†o Routers ---
        # G·ª≠i c√°c services ƒë√£ kh·ªüi t·∫°o v√†o c√°c file router
        logger.info("\nüîó Injecting dependencies into routers...")
        predict_router.set_dependencies(model_wrapper, scenario_manager, smart_estimator, recommendation_service)
        scenarios_router.set_dependencies(scenario_manager)
        logger.info("‚úÖ Dependencies injected")

        elapsed_time = time.time() - start_time
        logger.info("\n" + "=" * 80)
        logger.info(f"üéâ Server ready to accept requests! (took {elapsed_time:.2f}s)")
        logger.info(f"üìö API Docs: http://localhost:8000/docs")
        logger.info("=" * 80 + "\n")
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        logger.critical("=" * 80)
        logger.critical(f"‚ùå Startup failed after {elapsed_time:.2f}s: {str(e)}")
        logger.critical("=" * 80)
        raise

# ==================== ENDPOINTS ====================

app.include_router(predict_router.router)
app.include_router(scenarios_router.router)


@app.get("/", tags=["Root"])
async def root():
    """Root endpoint"""
    return {
        "message": "Network Quality Prediction API (Modes: Scenario, Simple, Real-time)",
        "version": "1.2.0",
        "rest_api_docs": "/docs",
        "websocket_path": "/ws/socket.io"
    }

@app.get("/health", response_model=HealthResponse, tags=["Health"])
async def health_check(detailed: bool = False):
    """Health check endpoint"""
    try:
        if not model_wrapper or not scenario_manager:
            raise HTTPException(status_code=503, detail="Services not initialized")
        
        model_health = model_wrapper.health_check()
        
        all_ready = all([
            model_health.get('ready', False),
            scenario_manager.scenarios,
            smart_estimator is not None
        ])
        
        status = "healthy" if all_ready else "degraded"
        
        health_response = HealthResponse(
            status=status,
            model_loaded=model_health.get('model_loaded', False),
            scenarios_loaded=len(scenario_manager.scenarios),
            version="1.1.0"
        )
        
        logger.info(f"Health check - Status: {status}")
        return health_response
        
    except Exception as e:
        logger.error(f"Health check error: {str(e)}")
        raise HTTPException(status_code=500, detail="Health check failed")

# ==========================================================
# --- C√ÄI ƒê·∫∂T SOCKET.IO (WEBSOCKET) ---
# ==========================================================

# 1. T·∫°o ƒë·ªëi t∆∞·ª£ng Socket.IO Server (sio)
sio = socketio.AsyncServer(
    async_mode="asgi",
    cors_allowed_origins="*", # Cho ph√©p React v√† Worker k·∫øt n·ªëi
    logger=True,
    engineio_logger=True
)

# 2. T·∫°o ·ª©ng d·ª•ng ASGI cho Socket.IO
socket_app = socketio.ASGIApp(
    sio,
    other_asgi_app=app,
    socketio_path="/ws/socket.io"
)

# 4. --- B·ªô l∆∞u tr·ªØ tr·∫°ng th√°i ---
global_state = {
    "metrics": None,
    "context": None,
    "react_sid": None  # ID c·ªßa client React ƒë·ªÉ g·ª≠i k·∫øt qu·∫£ v·ªÅ
}

async def trigger_prediction():
    """
    H√†m l√µi: Khi c√≥ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu (metrics + context),
    g·ªçi SmartEstimator v√† Model, sau ƒë√≥ g·ª≠i tr·∫£ k·∫øt qu·∫£.
    """
    global model_wrapper, smart_estimator, global_state, recommendation_service
    
    # Ki·ªÉm tra xem ƒë√£ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu V√Ä sid c·ªßa React ch∆∞a
    if not global_state["metrics"] or \
       not global_state["context"] or \
       not global_state["react_sid"]:
        
        logger.debug(f"Ch∆∞a ƒë·ªß d·ªØ li·ªáu: "
                     f"Metrics={'OK' if global_state['metrics'] else '...'} | "
                     f"Context={'OK' if global_state['context'] else '...'} | "
                     f"React SID={'OK' if global_state['react_sid'] else '...'}")
        return

    try:
        react_sid = global_state["react_sid"]
        logger.info(f"[{react_sid}] ƒê√£ ƒë·ªß 2 ph·∫ßn d·ªØ li·ªáu, b·∫Øt ƒë·∫ßu d·ª± ƒëo√°n...")
        
        # 1. Gom 9 th√¥ng s·ªë
        simple_input = {
            **global_state["metrics"], # G·ªìm: latency, throughput, battery_level, signal_strength
            **global_state["context"]  # G·ªìm: user_speed, user_activity, device_type, location, connection_type
        }
        
        # 2. ∆Ø·ªõc t√≠nh
        full_params = smart_estimator.estimate(simple_input)
        logger.info(f"[{react_sid}] ƒê√£ ∆∞·ªõc t√≠nh {len(full_params)} th√¥ng s·ªë.")
        
        # 3. D·ª± ƒëo√°n
        result = model_wrapper.predict(full_params)
        logger.info(f"[{react_sid}] K·∫øt qu·∫£: {result['prediction_label']}")

        recommendation = recommendation_service.get_recommendation(
            full_params,
            result['prediction_label']
        )

        # 4. Chu·∫©n b·ªã response
        response = PredictionResponse(
            prediction=result['prediction'],
            prediction_label=result['prediction_label'],
            confidence=result['confidence'],
            probabilities=result['probabilities'],
            message="Prediction based on real-time auto-collected metrics",
            mode="realtime", 
            metadata={
                "estimated_features_dict": full_params, 
                "contexts_used": global_state["context"]
            },
            insight=recommendation
        )
        
        # 5. G·ª≠i k·∫øt qu·∫£ NG∆Ø·ª¢C L·∫†I cho React Dashboard
        await sio.emit(
            "prediction_update",  # T√™n s·ª± ki·ªán
            response.model_dump(),  # Chuy·ªÉn Pydantic model v·ªÅ dict
            to=react_sid            # Ch·ªâ g·ª≠i cho client React
        )
        logger.info(f"[{react_sid}] ƒê√£ g·ª≠i 'prediction_update' cho client.")
        
        # X√≥a metrics ƒë·ªÉ ch·ªù l·∫ßn ƒëo m·ªõi
        global_state["metrics"] = None 

    except Exception as e:
        logger.error(f"[{global_state['react_sid']}] L·ªói khi d·ª± ƒëo√°n real-time: {e}")
        # G·ª≠i l·ªói v·ªÅ cho React
        await sio.emit("prediction_error", {"error": str(e)}, to=global_state["react_sid"])

# 5. --- C√°c tr√¨nh x·ª≠ l√Ω s·ª± ki·ªán (Event Handlers) ---

@sio.event
async def connect(sid, environ, auth):
    """Client (Worker ho·∫∑c React) k·∫øt n·ªëi"""
    logger.info(f"üì° Client ƒë√£ k·∫øt n·ªëi: {sid}")

@sio.event
async def disconnect(sid):
    """Client ng·∫Øt k·∫øt n·ªëi"""
    logger.warning(f"üîå Client ƒë√£ ng·∫Øt k·∫øtnoi: {sid}")
    # N·∫øu client React b·ªã ng·∫Øt k·∫øt n·ªëi, x√≥a sid c·ªßa n√≥
    if sid == global_state.get("react_sid"):
        global_state["react_sid"] = None
        logger.warning(f"Client React (Dashboard) ƒë√£ ng·∫Øt k·∫øt n·ªëi.")


# --- L·∫Øng nghe l·ªánh B·∫ÆT ƒê·∫¶U t·ª´ React ---
@sio.event
async def start_prediction(sid, data):
    """
    Nh·∫≠n y√™u c·∫ßu "B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n" t·ª´ React Dashboard (5 th√¥ng s·ªë b·ªëi c·∫£nh)
    """
    logger.info(f"[{sid}] Nh·∫≠n 'start_prediction': {data}")
    
    # 1. L∆∞u context V√Ä sid c·ªßa React
    global_state["context"] = data
    global_state["react_sid"] = sid
    
    # 2. X√≥a metrics c≈© (n·∫øu c√≥) ƒë·ªÉ chu·∫©n b·ªã cho l·∫ßn ƒëo m·ªõi
    global_state["metrics"] = None
    
    # 3. Ra l·ªánh cho T·∫§T C·∫¢ client (Worker s·∫Ω l·∫Øng nghe)
    await sio.emit("start_measurement")
    logger.info(f"[{sid}] ƒê√£ ph√°t l·ªánh 'start_measurement' cho worker.")

# --- L·∫Øng nghe k·∫øt qu·∫£ t·ª´ Worker ---
@sio.event
async def worker_metrics(sid, data):
    """
    Nh·∫≠n d·ªØ li·ªáu t·ª´ 'worker.py' (4 th√¥ng s·ªë)
    """
    logger.info(f"[{sid}] Nh·∫≠n 'worker_metrics': {data}")
    
    # 1. L∆∞u metrics
    global_state["metrics"] = data
    
    # 2. G·ªçi h√†m l√µi ƒë·ªÉ ki·ªÉm tra v√† d·ª± ƒëo√°n
    await trigger_prediction()

@sio.event
async def worker_error(sid, data):
    """
    Nh·∫≠n th√¥ng b√°o L·ªñI t·ª´ 'worker.py'
    """
    error_message = data.get('error', 'Unknown worker error')
    logger.error(f"[{sid}] Nh·∫≠n 'worker_error': {error_message}")
    
    react_sid = global_state.get("react_sid")
    if react_sid:
        # G·ª≠i l·ªói n√†y v·ªÅ cho React Dashboard
        await sio.emit(
            "prediction_error", 
            {"error": f"Worker Error: {error_message}"}, 
            to=react_sid
        )
        logger.info(f"[{react_sid}] ƒê√£ g·ª≠i 'prediction_error' cho client React.")
    
    # X√≥a metrics ƒë·ªÉ ch·ªù l·∫ßn ƒëo m·ªõi (n·∫øu c√≥)
    global_state["metrics"] = None

# ==================== RUN SERVER ====================
if __name__ == "__main__":
    print("="*80)
    print("üöÄ NETWORK QUALITY PREDICTION SERVER (v1.2.0 - Real-time)")
    print("="*80)
    print("\nüìç Server s·∫Ω start on: http://localhost:8000")
    print("üìö API Docs (REST): http://localhost:8000/docs")
    print(f"üì° Socket.IO (WS) listening on: /ws/socket.io")
    print("\n‚è≥ Starting server...\n")
    
    # uvicorn.run s·∫Ω t·ª± ƒë·ªông ch·∫°y 'app' (ƒë√£ bao g·ªìm c·∫£ FastAPI v√† Socket.IO)
    uvicorn.run(
        "server.main:app", 
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )