import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
import joblib
import os

def train_and_evaluate_final(
    train_path="data/synthetic/train_smote_balanced.csv", 
    test_path="data/processed/test.csv",
    model_dir="models",
    report_dir="reports"
):
    print("ğŸš€ Báº¯t Ä‘áº§u quy trÃ¬nh huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­ cuá»‘i cÃ¹ng...")
    
    # --- 1ï¸âƒ£ Load dá»¯ liá»‡u ---
    # Load Train (Ä‘Ã£ SMOTE)
    if not os.path.exists(train_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file {train_path}")
        return
    df_train = pd.read_csv(train_path)
    
    # Load Test (Dá»¯ liá»‡u thá»±c táº¿)
    if not os.path.exists(test_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file {test_path}")
        return
    df_test = pd.read_csv(test_path)

    print(f"ğŸ“Š Dá»¯ liá»‡u Train (Synthetic): {len(df_train)} máº«u")
    print(f"ğŸ“Š Dá»¯ liá»‡u Test (Real): {len(df_test)} máº«u")
    
    target_col = 'RF Link Quality'
    # Mapping Ä‘á»ƒ hiá»ƒn thá»‹ cho Ä‘áº¹p
    class_names = ['Poor', 'Moderate', 'Good'] 
    
    X_train = df_train.drop(columns=[target_col])
    y_train = df_train[target_col]
    
    X_test = df_test.drop(columns=[target_col])
    y_test = df_test[target_col]
    
    # --- 2ï¸âƒ£ Huáº¥n luyá»‡n Model ---
    print("\nğŸ¤– Äang train model Random Forest...")
    rf_final = RandomForestClassifier(
        n_estimators=500, 
        random_state=42, 
        n_jobs=-1,
        class_weight='balanced_subsample',
        max_depth=20,
        max_features='log2',
        min_samples_leaf=1,
        min_samples_split=2
    )
    rf_final.fit(X_train, y_train)
    
    # LÆ°u Model
    os.makedirs(model_dir, exist_ok=True)
    joblib.dump(rf_final, os.path.join(model_dir, "rf_final_model.pkl"))
    
    # --- 3ï¸âƒ£ ÄÃ¡nh giÃ¡ trÃªn táº­p TEST (Quan trá»ng nháº¥t) ---
    print("\nâš–ï¸ Äang Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test thá»±c táº¿...")
    y_pred = rf_final.predict(X_test)
    
    # TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘
    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… Accuracy trÃªn táº­p Test: {acc:.2%}")
    
    print("\nğŸ“ Classification Report (Test Set):")
    print(classification_report(y_test, y_pred, target_names=class_names))
    
    # --- 4ï¸âƒ£ Váº½ vÃ  LÆ°u Confusion Matrix ---
    os.makedirs(report_dir, exist_ok=True)
    
    cm = confusion_matrix(y_test, y_pred)
    
    plt.figure(figsize=(8, 6))
    # DÃ¹ng heatmap cá»§a seaborn cho Ä‘áº¹p hÆ¡n
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, 
                yticklabels=class_names)
    
    plt.title(f'Confusion Matrix (Test Set)\nAccuracy: {acc:.2%}')
    plt.ylabel('Thá»±c táº¿ (True Label)')
    plt.xlabel('Dá»± Ä‘oÃ¡n (Predicted Label)')
    plt.tight_layout()
    
    cm_path = os.path.join(report_dir, "confusion_matrix_final.png")
    plt.savefig(cm_path)
    print(f"ğŸ“Š ÄÃ£ lÆ°u Confusion Matrix táº¡i: {cm_path}")
    
    # --- 5ï¸âƒ£ Váº½ Feature Importance (Cáº­p nháº­t láº¡i) ---
    importances = rf_final.feature_importances_
    fi_df = pd.DataFrame({
        'Feature': X_train.columns,
        'Importance': importances
    }).sort_values(by='Importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=fi_df.head(10), x='Importance', y='Feature', palette='viridis')
    plt.title('Top 10 Feature Importance')
    plt.tight_layout()
    
    fi_path = os.path.join(report_dir, "feature_importance_final.png")
    plt.savefig(fi_path)
    print(f"ğŸ“Š ÄÃ£ lÆ°u Feature Importance táº¡i: {fi_path}")
    print("\nğŸ‰ HoÃ n táº¥t quy trÃ¬nh!")

if __name__ == "__main__":
    train_and_evaluate_final()