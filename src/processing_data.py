import pandas as pd
import os
import numpy as np
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
from sklearn.model_selection import train_test_split
import joblib

def process_data(input_path, output_folder="data/processed", model_dir='models'):
    """
    X·ª≠ l√Ω d·ªØ li·ªáu: 
    - Lo·∫°i b·ªè c√°c c·ªôt g√¢y Leakage (Signal Strength, SNR, PDR)
    - Encoding & Scaling
    - Chia Train/Test
    """
    
    # --- 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu ---
    df = pd.read_csv(input_path)
    print(f"üìä T·ªïng s·ªë m·∫´u ban ƒë·∫ßu: {len(df)}")
    
    # --- 2Ô∏è‚É£ V·ªá sinh d·ªØ li·ªáu ---
    target_col = 'RF Link Quality'
    df[target_col] = df[target_col].astype(str).str.strip()
    
    # X√≥a c√°c gi√° tr·ªã r√°c
    invalid_labels = ['0', 'nan', '', 'None']
    df = df[~df[target_col].isin(invalid_labels)].copy()
    
    # Map target
    rf_link_quality_map = {'Poor': 0, 'Moderate': 1, 'Good': 2}
    df[target_col] = df[target_col].map(rf_link_quality_map)
    df.dropna(subset=[target_col], inplace=True)
    df[target_col] = df[target_col].astype(int)
    
    # Map congestion
    congestion_map = {'Low': 0, 'Medium': 1, 'High': 2}
    df['Network Congestion'] = df['Network Congestion'].astype(str).str.strip().map(congestion_map)
    df.dropna(subset=['Network Congestion'], inplace=True)
    df['Network Congestion'] = df['Network Congestion'].astype(int)
    
    df['Modulation Scheme'] = df['Modulation Scheme'].astype(str).str.strip()
    
    print(f"‚úÖ ƒê√£ l√†m s·∫°ch d·ªØ li·ªáu. C√≤n l·∫°i {len(df)} m·∫´u.")

    # ==============================================================================
    # üö® QUAN TR·ªåNG: LO·∫†I B·ªé C√ÅC C·ªòT G√ÇY DATA LEAKAGE üö®
    # ==============================================================================
    leakage_cols = [
        # 'Signal Strength (dBm)', 
        'SNR (dB)',      # Khuy√™n b·ªè: V√¨ SNR cao th√¨ Quality ch·∫Øc ch·∫Øn t·ªët
        'BER',           # Khuy√™n b·ªè: Bit Error Rate th·∫•p th√¨ Quality t·ªët
        'PDR (%)',       # Khuy√™n b·ªè: Packet Delivery Ratio cao th√¨ Quality t·ªët
        'Retransmission Count' # Khuy√™n b·ªè: S·ªë l·∫ßn g·ª≠i l·∫°i li√™n quan tr·ª±c ti·∫øp ƒë·∫øn l·ªói m·∫°ng
    ]
    
    # C√°c c·ªôt c√≥ th·ªÉ kh√¥ng quan tr·ªçng (Feature Selection - Optional)
    irrelevant_cols = ['User Direction (degrees)', 'Modulation Scheme'] # H∆∞·ªõng ƒëi th∆∞·ªùng √≠t ·∫£nh h∆∞·ªüng n·∫øu Omni-directional antenna
    
    cols_to_remove = leakage_cols + irrelevant_cols
    
    print(f"\n‚úÇÔ∏è ƒêang lo·∫°i b·ªè c√°c c·ªôt Leakage & Kh√¥ng quan tr·ªçng: {cols_to_remove}")
    cols_to_drop = [col for col in cols_to_remove if col in df.columns]
    df.drop(columns=cols_to_drop, inplace=True)
    # ==============================================================================
    
    # --- 4Ô∏è‚É£ X√°c ƒë·ªãnh feature types ---
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    categorical_features = []
    numerical_features = []
    
    for col in X.columns:
        if X[col].dtype == 'object' or col in ['Network Congestion']:
            categorical_features.append(col)
        else:
            numerical_features.append(col)
            
    print(f"üîç Features c√≤n l·∫°i ƒë·ªÉ train ({len(X.columns)}): {list(X.columns)}")
    
    # --- 5Ô∏è‚É£ X·ª≠ l√Ω categorical features v·ªõi Label Encoding ---
    label_encoders = {}
    
    for col in categorical_features:
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
        label_encoders[col] = le
    
    # --- 6Ô∏è‚É£ Chu·∫©n h√≥a numerical features ---
    scaler = MinMaxScaler()
    
    if numerical_features:
        X_scaled_num = scaler.fit_transform(X[numerical_features])
        X_processed = pd.DataFrame(X_scaled_num, columns=numerical_features, index=X.index)
        for col in categorical_features:
            X_processed[col] = X[col].values
    else:
        X_processed = X.copy()
    
    df_processed = X_processed.copy()
    df_processed[target_col] = y.values
    
    # --- 7Ô∏è‚É£ CHIA TRAIN/TEST ---
    train_df, test_df = train_test_split(
        df_processed, 
        test_size=0.2, 
        random_state=42, 
        stratify=df_processed[target_col]
    )
    
    # --- 8Ô∏è‚É£ L∆∞u k·∫øt qu·∫£ ---
    os.makedirs(output_folder, exist_ok=True)
    os.makedirs(model_dir, exist_ok=True)
    
    train_path = os.path.join(output_folder, "train.csv")
    test_path = os.path.join(output_folder, "test.csv")
    
    train_df.to_csv(train_path, index=False)
    test_df.to_csv(test_path, index=False)
    
    # L∆∞u metadata (c·∫≠p nh·∫≠t l·∫°i danh s√°ch feature m·ªõi)
    joblib.dump(scaler, os.path.join(model_dir, "minmax_scaler.pkl"))
    joblib.dump(label_encoders, os.path.join(model_dir, "label_encoders.pkl"))
    
    feature_info = {
        'numerical_features': numerical_features,
        'categorical_features': categorical_features,
        'target_mapping': rf_link_quality_map,
        'all_features': list(X_processed.columns) + [target_col]
    }
    joblib.dump(feature_info, os.path.join(model_dir, "feature_info.pkl"))
    
    print(f"\n‚úÖ X·ª≠ l√Ω ho√†n t·∫•t (ƒê√£ lo·∫°i b·ªè Leakage)!")
    print(f"üìÅ Train set saved to: {train_path}")
    print(f"üìÅ Test set saved to: {test_path}")
    
    return train_df, test_df

if __name__ == "__main__":
    process_data("data/raw/wireless_communication_dataset.csv")